# -*- mode: python; -*-

optparser.add_option("-w", "--weights", dest="weights", help="weights")
optparser.add_option("-x", "--testset", dest="testset", help="name of test set to decode")
opts, args = optparser.parse_args()

# import lm_srilm as lm
import lm_biglm as lm
import rule, sym, svector
import decoder, model
import os, os.path

# Verbosity. 0 = silent, 1 = normal, 2-5 = verbose
log.level = 1
log.file = sys.stderr

n_best = 10
n_random = 0
ambiguity_limit = 1
shuffle_sentences = False

lmdir = "/home/nlg-02/data07/eng/v2/LMs"
#lmdir = os.environ['TMPDIR']

gramdir = "."

### Models

models = []

models.append(lm.LanguageModel(os.path.join(lmdir, "lm.bi.ae_c_ce.v5.1.mttok.lc.nodigits.eng.5grams.prune45.inter.c16p4b4.biglm"), mapdigits="@", feat="lm1"))
models.append(lm.LanguageModel(os.path.join(lmdir, "lm.cols01.1bw.5grams.prune45.kn.eng.c16p4b4.biglm"), mapdigits="@", feat="lm2"))

### Phrase translation models
"""models.append(model.PhraseModel("pt", 1, feat="pfe"))
models.append(model.PhraseModel("pt", 2, feat="pef"))
models.append(model.PhraseModel("pt", 3, feat="lfe"))
models.append(model.PhraseModel("pt", 4, feat="lef"))

models.append(model.PhrasePenalty("pt", feat="phrase"))

models.append(model.PhrasePenalty("green", feat="green"))
models.append(model.PhrasePenalty("olive", feat="olive"))

models.append(model.PhrasePenalty("unknown", feat="unknown"))

models.append(model.PhrasePenalty("mono", feat="mono"))"""

wordpenalty = model.WordPenalty(feat="word")
models.append(wordpenalty)

positive_features = "lm1 lm2".split()
feature_scales = svector.Vector('lm1=0.5 lm2=0.5 pfe=0.5 pef=0.5 lfe=0.5 lef=0.5')
#feature_weights = svector.Vector('lm1=1 lm2=1 pfe=1 pef=1 lfe=1 lef=1')
feature_weights = svector.Vector('lm1=1 lm2=1 pt1=1 pt2=1 pt3=1 pt4=1')

# set weights from command-line
if hasattr(opts, 'weights') and opts.weights is not None:
    feature_weights = svector.Vector()
    if "=" in opts.weights:
        wstr = opts.weights
    else:
        wstr = file(opts.weights).read()
    for fv in wstr.split():
        f,v = fv.split("=",1)
        feature_weights[f] = float(v)

### Grammar
rule_limit = 50
rule_threshold = None

span_limit = 15

class LocalGrammar(decoder.Grammar):
    def filterspan(self, i, j, n):
        return j-i <= span_limit

class RegularGrammar(decoder.Grammar):
    def filterspan(self, i, j, n):
        return i == 0
glue_grammar = RegularGrammar()
glue1 = rule.Rule(sym.fromstring('[START]'),
                rule.Phrase('[START,1] [PHRASE,2]'),
                rule.Phrase('[START,1] [PHRASE,2]'),
                scores=svector.Vector("mono", 1.))
glue2 = rule.Rule(sym.fromstring('[START]'),
                rule.Phrase('[PHRASE,1]'),
                rule.Phrase('[PHRASE,1]'),
                scores=svector.Vector("stopmono", 1.))
# would be nice to get rid of these
decoder.estimate_rule(glue1, models, feature_weights) 
decoder.estimate_rule(glue2, models, feature_weights)
glue_grammar.add(glue1)
glue_grammar.add(glue2)

xmlrules = decoder.XMLRules()

class MyDecoder(decoder.Decoder):
    def prepare_input(self, sent):
        g = LocalGrammar(threshold=rule_threshold, limit=rule_limit)
        g.read(os.path.join(gramdir, "sentgrammars.full.M4.L15l6A-l6v0A.crossing.%s" % opts.testset, "grammar.line%s" % sent.id), self.models, self.weights)
        self.set_grammar([g, glue_grammar, xmlrules])

        global span_limit
        if len(sent.fwords) >= 200:
            span_limit = 5
        elif len(sent.fwords) >= 100:
            span_limit = 10
        else:
            span_limit = 15

thedecoder = MyDecoder([], sym.fromstring('[START]'), [sym.fromstring('[PHRASE]')], models, feature_weights)

thedecoder.prune_threshold = None
thedecoder.prune_limit = 100
thedecoder.pop_limit = 1000
thedecoder.fuzz1 = thedecoder.fuzz2 = 100000.

