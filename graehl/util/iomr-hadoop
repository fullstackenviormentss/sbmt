#!/bin/bash
export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-/scratch/hadoop/conf}
BLOBS=${BLOBS:-~graehl/blobs}
. $BLOBS/bashlib/unstable/bashlib.sh

#hadfs() {
#    $d/fhadoop "$@"
#}

hadrmf() {
    local in=$1
    if hadexists "$in" ; then
        if [ "$noclobber" ] ;then
            error HDFS: $in already exists
        else
            echo2 HDFS: removing existing $in
#            hadfs -rmr "$in"
            hadrm "$in"
        fi
    fi
}

usage() {
    cat<<EOF
    usage: [local=1 [savemap=map.output]] [noclobber=1] [rmin=1] [file=file-cp-to-wd] [combine=1] $0 in out map reduce [hadoop args]
    in and out should be dir-less filenames or '-' for stdin/stdout (local only)
EOF
    exit 1
}

filex() {
    local map=$1
    if [[ $map != ${map#/} ]] ; then
        local wmap=`which $map`
        if [[ -x $wmap && ${wmap#/bin} = $wmap && ${wmap#/usr/bin} = $wmap ]] ; then
            files+=" $wmap"
            echo2 "copying $wmap to $map for hadoop - is . in PATH?"
        fi
    fi
}

realx() {
    local map=$1
    local omap=$map
    shift
    if ! [[ -x $map ]] ; then
        map=$(rwhich $map)
        [[ $omap != $map ]] && echo2 resolved $omap to $map for hadoop.
    fi
    if [ "$*" ] ; then
        xcmd="sh -c '$map $(realpath "$@")'"
#note: this will fail if realpath has any items w/ spaces in them. hard to fix.
        true
    else
        false
    fi
}

main() {
  set -e
  local in=$1
  [[ $in ]] || usage
  local out=$2
  local map=$3
  local reduce=$4
  shift
  shift
  shift
  shift
  showvars_required in out map
  if [[ ! $reduce ]] ; then
      reduce=NONE
  fi

  showvars_optional local file combine buflines stage infs outfs noclobber rmin
  showvars_required in out map reduce
  if [[ ! $local ]] ; then
      showvars_required HADOOP_CONF_DIR
  fi
  files=$file
  if [ "$stage" ] ; then
      filex $map
      if [[ $reduce != NONE ]] ; then
          filex $reduce
      fi
  else
      if realx $map ; then map=$xcmd ; fi
      if [[ $reduce != NONE ]] ; then
          if realx $reduce ; then reduce=$xcmd ; fi
      fi
  fi
  showvars_optional file
  for f in $files ; do
      filearg+=" -file \"$f\""
      showvars_required f filearg
  done

  if [[ $combine ]] ; then
      map="sh -c '$map | $d/precombine.py -b ${buflines:=100000} | $reduce'"
  fi

  if [[ $local ]] ; then
      if [[ $infs ]] ; then cp "$infs" "$in"; fi
      previewf "$in"
      echo2 "catz $in | $map | mapsort | $reduce | catz_to $out"
      echo2
      if [[ $reduce = NONE ]] ; then
          reduce=cat
      fi
      echo2 reduce=$reduce
      catz "$in" | eval $map | mapsort | $reduce | catz_to "$out"
      if [[ $outfs && $outfs != $out ]] ; then  cp "$out" "$outfs"; fi
      previewf "$out"
  else
      if [[ $in = - ]]; then
          in="stdin.`nanotime`"
          $infs=-
      fi
      if [[ $infs ]] ; then
          hadrmf "$in"
          hadfs -put "$infs" "$in"
      elif ! hadexists "$in" ; then
          require_file "$in"
          echo2 using implicit infs=$in - copying local file to hadoop
          hadfs -put "$in" "$in"
      fi
      if [[ $out = - ]] ; then
          out="stdout.`nanotime`"
          outfs=-
      fi
      hadrmf "$out"
      hadpreview "$in"
      set -x
      $HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/contrib/streaming/hadoop-streaming.jar \
          -input "$in" -output "$out" -mapper "$map" -reducer "$reduce" $filearg "$@"
      set +x
      if [[ $rmin ]] ; then
          echo2 "rmin=1 so hadrm $in"
          hadrm "$in"
      fi
      echo2
      hadpreview "$out"
      if [[ $outfs ]] ; then
          hadcat "$out" | catz_to "$outfs"
      fi
  fi
}
main "$@"
